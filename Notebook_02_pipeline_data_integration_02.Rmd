---
title: "AF2 CATH project"
output:
  pdf_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Function to vizualize 1D and 3D alignment of structure
```{r}
library(dplyr)
library(bio3d)
library(ggplot2)
library(NGLVieweR)
library(Biostrings)
library(ggbreak)

```


## Define variable and load data
```{r}
#data and code dir from git repository
dcd <- "." # PROVIDE THE PATH TO GIT REPO ON YOUR COMPUTER
data <- file.path(dcd, "data") # Dir to save data


CATHUNP2 <- read.table(file.path(data, "CATHUNP2.tab"), header = T)
DomDir_cth <- file.path(data, "/v4_3_0")
DomDir_af2 <- file.path(data, "/v4_3_0_af2_dom/")

lf <- list.files(path = file.path(data),
                 pattern = '*.tab', full.names = TRUE)
message("Following data files will be loaded in this notebook")
print(lf)


# RMSD pariwise alignment global-local,  no truncation
rmsd1 <- read.table(file.path(data, "data01_Ext_AF2Dom_RMSD.tab"), header = T)[-2]


# # updated rmsd6 potential non-core domain gesments were removed with appropriate alignment
rmsd6 <- read.table(file.path(data, "data02_RMSD6.tab"), header=T)#[c(1,10, 11, 12)]

# some of the colnames are changed to *_t to distinguish it from rmsd1 data
names(rmsd6) <- c("Dom", "SP_PRIMARY_t", "af2ResBoundary_t", "af2DomLen_t", "PID_t", 
"PID1_t", "pLDDTq10_", "pLDDTq20_t", "pLDDTq30_t", "RMSD6", "Nter_trunc", "Cter_trunc")


# relative surface area, ratio and secondary structure
relasa <- read.table(file.path(data,"data03_SecStr_ReASA.tab"), header = T)

#Volume and surface area of domain
volsurf <- read.table(file = file.path(data, "data04_VolSurf.tab"), sep = "\t", header = T)


# Seq cluster
clstrFile <- file.path(data, "data05_SeqClust.tab")
clstr <- read.table(clstrFile, header = T)


# Sec str content
message("Secondary structure data")
secstr <- read.table(file.path(data, "data06_SecStr_loss.tab"), header = T)

# merge various
df1 <- merge(CATHUNP2, rmsd1, by = 'Dom'); rm(CATHUNP2)
df1 <- merge(df1, rmsd6[!names(rmsd6) %in% "SP_PRIMARY"], by = 'Dom')
#df1 <- merge(df1, ligdf[!names(ligdf) %in% "SP_PRIMARY"], by = 'Dom')
#df1 <- merge(df1, metaldf[!names(metaldf) %in% "SP_PRIMARY"], by = 'Dom')
df1 <- merge(df1, relasa[!names(relasa) %in% "SP_PRIMARY"], by = 'Dom')
df1 <- merge(df1, volsurf[!names(volsurf) %in% "SP_PRIMARY"], by = 'Dom')
df1 <- merge(df1, clstr, by = 'Dom')
df1 <- merge(df1, secstr, by = 'Dom')




df1$SP_C95 <- paste0(df1$SP_PRIMARY, "_", df1$C95)

df1 <- df1 %>% distinct(Dom, .keep_all = TRUE)

#RSMD normalization RMSD100 or R100
df1$R100 <- with(df1, (RMSD/(1+log(sqrt(Dom_Len/100))))) %>% round(3)






# Mark subdomains by clustering by size
#--------------------------------------------
#'@ separates short and long domain obtained after CD HIT 95 % clustering 
#'@ differentiates between sub-domain of different length, >=20
markSubDom <- function(v, sdcol){
  # sub domain cutoff length. If two sub-domains are 20 amino acid 
  # different in length then they can be called sub-domain
  #sdcol <- 20
  # v <- z2$Dom_Len
  if(max(v) - min(v) >=sdcol){
  distance <- dist(v, method = "euclidean") # distance matrix
  fit <- hclust(distance, method="ward.D2")
  groups <- cutree(fit, h=sdcol)
  subDClust <- paste0('0', groups)
  }else{
  subDClust <- rep("00", length(v))
  }
  return(subDClust)
}


message("Clustering domains to get diversity of sub_domains within length difference of 20")
df1$SP_C95_XX <- NA
spc95IDs <- unique(df1$SP_C95)

#monitor progress
pb <- txtProgressBar(min = 1, max = length(spc95IDs), 
                     style = 3, width = 50, 
                     char = "=")

for(i in seq_along(spc95IDs)){
 # i= 1
  tempdf <- df1[df1$SP_C95 == spc95IDs[i],]
  ms <- markSubDom(tempdf$Dom_Len, 20)
  df1$SP_C95_XX[df1$SP_C95 == spc95IDs[i]] <- paste0(tempdf$SP_C95, "_", ms)
  setTxtProgressBar(pb, i)
}


message("Assigning average dom length to sub_domain SP_C95_XX")

df1$SP_C95_XX_domL <- NA
SP_C95_XX_uid <- unique(df1$SP_C95_XX)

for(i in seq_along(SP_C95_XX_uid)){
  av_dom_len <- df1$Dom_Len[df1$SP_C95_XX == SP_C95_XX_uid[i]] %>% mean() %>% round(., 2)
  df1$SP_C95_XX_domL[df1$SP_C95_XX == SP_C95_XX_uid[i]] <- av_dom_len
}



message("Clustering domains to get diversity of sub_domains within length difference of 10")
df1$SP_C95_XX10 <- NA
spc95IDs <- unique(df1$SP_C95)

#monitor progress
pb <- txtProgressBar(min = 1, max = length(spc95IDs), 
                     style = 3, width = 50, 
                     char = "=")

ms <- NULL
for(i in seq_along(spc95IDs)){
 # i= 1
  tempdf <- df1[df1$SP_C95 == spc95IDs[i],]
  ms <- markSubDom(tempdf$Dom_Len, 10)
  df1$SP_C95_XX10[df1$SP_C95 == spc95IDs[i]] <- paste0(tempdf$SP_C95, "_", ms)
  setTxtProgressBar(pb, i)
}

message("Assigning average dom length to sub_domain SP_C95_XX10")
df1$SP_C95_XX10_domL <- NA
SP_C95_XX10_uid <- unique(df1$SP_C95_XX10)

for(i in seq_along(SP_C95_XX10_uid)){
  av_dom_len <- df1$Dom_Len[df1$SP_C95_XX10 == SP_C95_XX10_uid[i]] %>% mean() %>% round(., 2)
  df1$SP_C95_XX10_domL[df1$SP_C95_XX10 == SP_C95_XX10_uid[i]] <- av_dom_len
}
#--------------------------------------------



################################## Define "the fold" and number of chunk associated with a CATH domain.
df1$fold <- paste( df1$Class, df1$Arch, df1$Topol, sep = '.')
df1$nchunks <- stringr::str_count(df1$af2ResBoundary, "-")

################################## distance difference matrix
LDDThi <- read.table(file.path(data, "data08_LDDThi_10%resi.tab"), header = T)
df1 <- merge(df1, LDDThi, by = 'Dom')

################################## FATCAT
fatcat <- read.table(file.path(data, "data09_FATCAT_RMSD.tab"), header = T)

################################## The merged dataset "The 200K dataset"
df1 <- merge(df1, fatcat, by = 'Dom')



################################## Bad alignment removed "The 170K dataset"
df <- df1 %>% filter(PID1>99)



################################## The fatcat dataset "The 130K dataset"
df01 <- df1 %>% filter(FCidendity == 100)  #%>% filter(FCtwist < 2)


################################## The final dataset with healty alignment, 
# better resolution and no extended Termini "The 110K dataset"
df02 <- df1 %>% filter(pLDDTq10 >= 80) %>% 
  filter(PID1>99) %>% filter(Str_Resol <= 3) %>% 
  filter(!(Nter_trunc | Cter_trunc))
```











 


